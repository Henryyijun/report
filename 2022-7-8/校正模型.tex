%\documentclass[journal]{IEEEtran}
%\documentclass[12pt,onecolumn]{IEEEtran}
\documentclass[UTF8]{article}
\usepackage{ctex}
\usepackage{geometry,graphicx,marvosym}
\usepackage{amsmath,amsthm}
\usepackage{amsfonts}
\usepackage[usenames,dvipsnames]{pstricks}
\usepackage{pst-plot,pstricks-add}
%\usepackage{graphicx,times,amsmath,amssymb,multirow,subfigure}
\usepackage{graphicx,times,amsmath,amssymb,multirow}
\usepackage{url}
\usepackage{stfloats}
\usepackage{amsfonts,rotating}
\usepackage{color}
\usepackage{verbatim,multirow}
% setting dimension of the paper
\textwidth 7.0true in
\textheight 8.9 true in
\topmargin=-20pt
\headheight=6pt
\headsep=2pt
\oddsidemargin -0.3true in
\evensidemargin -0.4true in
\usepackage{amssymb}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{algorithm}{Algorithm}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}

\newcommand{\dtcwt}{\operatorname{DT-\mathbb{C}WT}}
\newcommand{\tpctf}{\operatorname{TP-\mathbb{C}TF}}
\newcommand{\ctf}{\operatorname{\mathbb{C}TF}}
\newcommand{\tr}[1]{\textcolor{red}{#1}}
\newcommand{\tb}[1]{\textcolor{blue}{#1}}
\newcommand{\mO}{{\mathcal{T}}}
\newcommand{\C}{\mathbb{C}}    %complex number field
\newcommand{\N}{\mathbb{N}}    %natural numbers
\newcommand{\R}{\mathbb{R}}    %real number field
\newcommand{\Z}{\mathbb{Z}}    %integers
\newcommand{\imag}{\mathrm{i}} % imaginary unit
\newcommand{\dR}{\mathbb{R}^d}
\newcommand{\dT}{\mathbb{T}^d}
\newcommand{\dZ}{\mathbb{Z}^d}
\newcommand{\dlp}[1]{l_{#1}(\mathbb{Z}^d)}
\newcommand{\td}{\boldsymbol{\delta}}  %Dirac/Kronicker sequence
\newcommand{\bp}{\begin{proof}}
	\newcommand{\ep}{\hfill  \end{proof} }
\newcommand{\be}{ \begin{equation} }
\newcommand{\ee}{ \end{equation} }
\newcommand{\dLp}[1]{L_{#1}(\mathbb{R}^d)}
\newcommand{\prm}{P}           %projection matrix
\newcommand{\wh}{\widehat}
\renewcommand{\le}{\leqslant}
\renewcommand{\ge}{\geqslant}
\newcommand{\bs}{\backslash}
\newcommand{\ol}{\overline}
\newcommand{\vk}{\mathsf{k}}
\newcommand{\la}{\langle}
\newcommand{\ra}{\rangle}
\newcommand{\tp}{\mathsf{T}}  %transpose
\newcommand{\conj}{\overline}
\newcommand{\supp}{\mathrm{supp}}
\newcommand{\setsp}{\;:\;}     %set separator
\newcommand{\sd}{\mathcal{S}}  %subdivision operator S
\newcommand{\tz}{\mathcal{T}}  %transition operator T
\newcommand{\wt}{\widetilde}
\renewcommand{\le}{\leqslant}
\renewcommand{\ge}{\geqslant}
\newcommand{\er}{\eqref}
\newcommand{\gep}{\varepsilon}
\newcommand{\eps}{\epsilon}
\newcommand{\gl}{\lambda}
\newcommand{\gL}{\Lambda}
\newcommand{\gd}{\delta}
\newcommand{\DAS}{\mathrm{DAS}}
\newcommand{\UDAS}{\mathrm{UDAS}}
\newcommand{\DHF}{\mathrm{DHF}}

\newtheorem{example}{Example}
\bibliographystyle{unsrt}
\newcommand{\xz}[1]{\textcolor{magenta}{\bf #1}}
\usepackage[colorlinks,linkcolor=blue,anchorcolor=blue,citecolor=blue]{hyperref}
\usepackage{indentfirst}

\usepackage{algorithm}
\usepackage{algpseudocode}


\begin{document}
\author{Henry}
\title{Calibration Observation Model for Parallel Magnetic Resonance Imaging}

\maketitle

\section{Introduction}
\par Magnetic Resonance Imaging (MRI) is a non-invasive medical imaging technology, which not only does'nt use ionizing radiation, but also can obtain high-resolution and high-quality pathological images. However, MRI is different from Computed Tomography(CT) and other imaging methods in that they have the characteristic of fast imaging time. The biggest obstacle of MRI is that its data acquisition is too slow, which result in patients feel uncomfortable.Thus, the main research purpose of MRI technology is to shorten the imaging time and improve the imaging quality. 
\par Parallel MRI (pMRI) technology is used to shorten the imaging time by the hardware, it uses a series of coils to acqucire the undersampling MR signal at the meantime, then uses the reconstruction algorithm to predict high-resolution MR image by partial k-space data. The most commonly used reconstruction algorithms can divided into two catagories, the image domain method(e.g. SENSE) and the k-space domain method(e.g. GRAPPA).

\par SENSE and GRAPPA are widely used in clinical application, but these two models have some shortcomings. For the SENSE method, the coil sensitivity can be estimated, but it is still not accuracy. For the another method, the interpolation kernel can be estimated by the auto calibraion signal(ACS) while it's not accuracy when the number of the ACS line is far from enough. Therefore, we propose the calibration observation model incoporating the advantage of the SENSE and GRAPPA. We exploit the SENSE model to remove artifacts in image domain and use GRAPPA kernel to regularize the SENSE model in K-space domain.
\subsection{SENSE-based pMRI reconstruction model}

\par The coil data from the $j$th coil can modeled as follows:
\begin{equation}\label{eq:coil_equation}
	g_l = PFS_lu + \eta
\end{equation}
where $u$ denotes the desired reconstruced image, $\eta$ is gaussian white noisy, $F$ is dicrete Fourier tranform matrix, and $P$ denotes the sampling matrix. 
\par Combining equations from $p$ coils, we have 
\begin{equation}\label{eq:system_equation}
	g = \mathcal{P}Mu + \eta
\end{equation}
where,
\begin{equation*}
	g = \begin{bmatrix}
		g_1 \\
		\vdots \\
		g_p
	\end{bmatrix},
   \mathcal{P} = \begin{bmatrix}
	   	P & \quad&\quad \\
	   	\quad& \ddots &\quad \\
	   	\quad& \quad& P
   \end{bmatrix},
	M = \begin{bmatrix}
		FS_1 \\
		\vdots \\
		FS_p
	\end{bmatrix},
	\eta =\begin{bmatrix}
		\eta_1 \\
		\vdots \\
		\eta_p
	\end{bmatrix}
\end{equation*}
\section{GRAPPA model}
\par GRAPPA utilizes the interpolation kernel to estimate the missing point, assuming we use $G$ to represent the interpolation kernel, then we have
\begin{equation} \label{GRAPPA_equation}
	\mathcal{P}GMu \approx g
\end{equation}

\section{Regularization with two level tight framelet systems}
\subsection{DHF}
\par The tight framelets in the first level is the directional Haar framelet (DHF) system, the filters associated with the DHF are
\begin{align*}
	\tau_0 = \frac{1}{4}\begin{bmatrix}
		1 & 1\\
		1 & 1
	\end{bmatrix},
	\tau_1 = \frac{1}{4}\begin{bmatrix}
		1 & 0\\
		0 & -1
	\end{bmatrix},
	\tau_2 = \frac{1}{4}\begin{bmatrix}
		0 & -1\\
		1 & 0
	\end{bmatrix},
	\tau_3 = \frac{1}{4}\begin{bmatrix}
		1 & -1\\
		0 & 0
	\end{bmatrix},\\
	\tau_4 = \frac{1}{4}\begin{bmatrix}
		1 & 0\\
		-1 & 0
	\end{bmatrix},
	\tau_5 = \frac{1}{4}\begin{bmatrix}
		0 & 0\\
		1 & -1
	\end{bmatrix},
	\tau_6 = \frac{1}{4}\begin{bmatrix}
		0 & 1\\
		0 & -1
	\end{bmatrix}.
\end{align*}
Let $M_k$ denotes the associated matrix representation of the filters $\tau_k$, therefore
\begin{equation*}
	B_{1l} = M_0 , B_{1h} = [M_1^T,\cdots, M_6^T]^T
\end{equation*}
\par Let $\Phi_{1 \Lambda} : R^{6n} \rightarrow R$ can be defined through a function $\varphi_1:R^6 \rightarrow R$ and a non-negative parameter vector $\Lambda =[ \lambda_1, \lambda_2, \cdots, \lambda_n]$ as  follows
\begin{equation*}
	\Phi_{1 \Lambda}(v) = \sum_{i= 1}^{n} \lambda_i \varphi_1(v_i, v_{i+n}, \cdots, v_{i+5n})
\end{equation*}
In this model, $\varphi_1(x_1, x_2,x_3,x_4,x_5,x_6) = \sqrt{|x_1|^2+|x_2|^2}+\sqrt{|x_3|^2+|x_4|^2}$

\subsection{DCT-based tight framelet}
\par The tight framelet in the second level is generated from the standard $3 \times 3$ DCT-II orthogonal matrix , the filters are
\begin{align*}
	\tau_0=\frac{1}{9}\begin{bmatrix}
		1 & 1 & 1\\
		1 & 1 & 1\\
		1 & 1 & 1
	\end{bmatrix},
	\tau_1=\frac{\sqrt{6}}{18}\begin{bmatrix}
		1 & 0 & -1\\
		1 & 0 & -1\\
		1 & 0 & -1
	\end{bmatrix},
	\tau_2=\frac{\sqrt{2}}{18}\begin{bmatrix}
		1 & -2 & 1\\
		1 & -2 & 1\\
		1 & -2 & 1
	\end{bmatrix},\\
	\tau_3=\frac{\sqrt{6}}{18}\begin{bmatrix}
		1 & 1 & 1\\
		0 & 0 & 0\\
		-1 & -1 & -1
	\end{bmatrix},
	\tau_4=\frac{1}{6}\begin{bmatrix}
		1 & 0 & -1\\
		0 & 0 & 0\\
		-1 & 0 & 1
	\end{bmatrix},
	\tau_5=\frac{\sqrt{3}}{18}\begin{bmatrix}
		1 & -2 & 1\\
		0 & 0 & 0\\
		-1 & 2 & -1
	\end{bmatrix},  \\
	\tau_6=\frac{\sqrt{2}}{18}\begin{bmatrix}
		1 & 1 & 1\\
		-2 & -2 & -2\\
		1 & 1 & 1
	\end{bmatrix}, 
	\tau_7=\frac{\sqrt{3}}{18}\begin{bmatrix}
		1 & 0 & -1\\
		-2 & 0 & 2\\
		1 & 0 & -1
	\end{bmatrix},
	\tau_7=\frac{1}{18}\begin{bmatrix}
		1 & -2 & 1\\
		-2 & 4 & -2\\
		1 & -2 & 1
	\end{bmatrix},
\end{align*}
Let $P_k$ denotes the associated matrix representation of the filters $\tau_k$, therefore
\begin{equation*}
	B_{1l} = P_0 , B_{1h} = [P_1^T,\cdots, P_8^T]^T
\end{equation*}
Let $\Phi_{2 \Theta} : R^{8n} \rightarrow R$ be defined through a nonnegative parameter sequence $\Theta = \{\theta_i = (\theta_{i1}, \theta_{i2}, \cdots , \theta_{i8}) \in R^{8n} : 1\le i \le n\}$  non-negative elements as follows
\begin{equation*}
	\Phi_{2 \Theta}(v) = \sum_{i=1}^{n} \|[\theta_{i1}v_i, \theta_{i2} v_{i+n}, \cdots, \theta_{i8} v_{i+7n} ]\|_1
\end{equation*}


\section{Calibration Observation Model}
\subsection{Model}
\par According to the model (\ref{eq:system_equation}) and (\ref{GRAPPA_equation}), we propose the following optimization model as
\begin{equation}\label{mod_double_reg}
	\min_{u} \left\{\frac{1}{2}\|\mathcal{P}Mu-g\|_2^2+  \frac{\lambda}{2}\|\mathcal{P}GMu-g \|_2^2 + \Phi_{1 \Lambda}(B_{1h} u) + \Phi_{2 \Theta}(B_{2h}B_{1l} u) \right\} 
\end{equation}
where $\lambda$ is equal to 1 by default. Define 
\begin{equation*}
	f(u) = \frac{1}{2}\|\mathcal{P}Mu-g\|_2^2+  \frac{\lambda}{2}\|\mathcal{P}GMu-g \|_2^2, \quad h(s) = \Phi_{1 \Lambda}(B_{1h} s_1) + \Phi_{2 \Theta}(B_{2h}B_{1l} s_2),\quad A = \begin{bmatrix}
		B_{1h} \\
		B_{2h}B_{1l}
	\end{bmatrix}
\end{equation*}
where $s = (s_1, s_2)$. Therefore, the model(\ref{mod_double_reg}) can be rewriten as 
\begin{equation}
	\min_{u} \left\{ f(u) + h(Au) \right\}
\end{equation}
$f(u) = \frac{1}{2}\|\mathcal{P}Mu-g\|_2^2+  \frac{\lambda}{2}\|\mathcal{P}GMu-g \|_2^2$ can be rewritten as:
\begin{equation}\label{eq:fun}
	f(u) = \frac{1}{2}\left 
	\|\begin{bmatrix}
		\mathcal{P}M \\
		\sqrt{\lambda}\mathcal{P}GM 
	\end{bmatrix} u - 
	\begin{bmatrix}
		g \\ \sqrt{\lambda}g
	\end{bmatrix}
	\right \|_2^2
\end{equation}
Equation (\ref{eq:fun}) can be written in a more concise form :
\begin{equation}
	f(u) = \frac{1}{2}\| Ku - y\|_2^2
\end{equation}
where 
\begin{equation*}\label{eq7}
	K = \begin{bmatrix}
		\mathcal{P}M \\
		\sqrt{\lambda}\mathcal{P}GM 
	\end{bmatrix},
	y = \begin{bmatrix}
		g \\
		\sqrt{\lambda}g
	\end{bmatrix}
\end{equation*}



\par Accoding to the function $f$, we have that $\nabla f(u) = K^T(Ku-y) = M^T \mathcal{P}^T (\mathcal{P}Mu-g) + \lambda M^T G^T \mathcal{P}^T(\mathcal{P}GMu-g)$, and we can find that the gradient of $f$ is $\|K\|^2$-Lipschitz continuous.

Choosing $\gamma $ and $\delta$ such that $\gamma < 2/ \|K\|^2$ and $\gamma \delta < 1$. The PD3O has the following iteration:
\begin{align*}
	u^{k} & = real(v^k)\\
	s^{k+1} &= prox_{\delta h^*} ((I-\gamma \delta AA^T)s^k + \delta A(2u^k-v^k-\gamma \nabla f(u^k)))\\
	v^{k+1} &= u^k-\gamma \nabla f(u^k) - \gamma A^T s^{k+1}
\end{align*}
where $\nabla f(u) = M^T \mathcal{P}^T (\mathcal{P}Mu-g) + \lambda M^T G^T \mathcal{P}^T(\mathcal{P}GMu-g)$.

According to the Moreau decomposition, we can get 
\begin{equation}
	s^{k+1} = x^k - \delta prox_{\delta^{-1} h} (\delta^{-1} x^k)
\end{equation}
where $x^k = (I-\gamma \delta AA^T)s^k + \delta A(2u^k-v^k-\gamma \nabla f(u^k))$
\begin{algorithm}
	\caption{\textbf{Double Domain Reconstruction Algorithm}}
	\label{Alg:scanMatching}
	\begin{algorithmic}[1]
		\Require 
		$g$ is acquired k-space data; $A$ is tight frame operator;
		$k:= 0$ ; $u^0:= sos(F^{-1}g)$; $v^0 = u^0; s^0 = Au^0$; $\epsilon:=1e-5$
		\Ensure $\gamma < 2/ \|K\|^2$ and $\gamma \delta < 1$
		\State \textbf{while}  $k \leq k_{max}$ \textbf{and} $\|u^{k+1} - u^{k}\| \ge \epsilon$ \textbf{do}  
		\State \ \ \ \ $u^{k} = real(v^{k})$
		\State \ \ \ \ $x^k = (I-\gamma \delta AA^T)s^k + \delta A(2u^k-v^k-\gamma \nabla f(u^k))$
		\State \ \ \ \ $s^{k+1} = x^k - \delta prox_{\delta^{-1} h} (\delta^{-1} x^k)$
		\State \ \ \ \ $ v^{k+1} = u^k-\gamma \nabla f(u^k) - \gamma A^T s^{k+1}$		
		\State \textbf{end while} 
	\end{algorithmic}
\end{algorithm}
\subsection{The calculation of the Lipschitz constant of the gradient of $f$}
\par To solve the model (\ref{mod_double_reg}), we need to estimate the Lipschitz constant of the $f$. Note that $\nabla f(u) = K^T(Ku - y)$, then the gradient of $f$ is $\|K\|^2_2$-Lipschitz continuous, 
\begin{equation*}
	\begin{aligned}
	\|K\|^2_2 = \| K^T K\|_2 &= \left \| 
	\begin{bmatrix}
		\mathcal{P} M \\
		\mathcal{P} GM
	\end{bmatrix}^T_2
	\begin{bmatrix}
		\mathcal{P} M \\
		\mathcal{P} GM
	\end{bmatrix} \right\| \\
		 & =\left\| 
		 \begin{bmatrix}
			  M^T\mathcal{P}^T &
			  M^T G^T\mathcal{P}^T
		 \end{bmatrix} 
	 	\begin{bmatrix}
	 		\mathcal{P} M \\
	 		\mathcal{P} GM
	 	\end{bmatrix}
		\right\|_2 \\
		& = \left\|
		\begin{bmatrix}
			M^T \mathcal{P}^T \mathcal{P}M + M^T G^T\mathcal{P}^T \mathcal{P}GM
		\end{bmatrix}
		\right\|_2 \\
		&\le  
		\left \|
			M^T \mathcal{P}^T \mathcal{P}M 
		\right\|_2
		+
		\left \|
			M^T G^T\mathcal{P}^T \mathcal{P}GM 
		\right\|_2 \\
		& = \left \|
		M^T \mathcal{P}^T \mathcal{P}M 
		\right\|_2 +  \left \|
		S^TF^T G^T\mathcal{P}^T \mathcal{P}GFS
		\right\|_2 \\
		& = \left \|
		S^TF^T  \mathcal{P}FS
		\right\|_2+  \left \|
		S^TF^T G^T \mathcal{P}GFS
		\right\|_2 \\
	\end{aligned}
\end{equation*}
\par Based on the previous work, we have known a constant $k$ related to the sensitivity $S_i$ which is defined as 
\begin{equation}
	k=\max_j \sum_{i}^{p}| s_j^i|^2
\end{equation}
where $s_j^i$  the $k$th diagonal element of the sensitivity matrix $S_i$, is the sensitivity coefficient of the $i$th coil at the $k$th pixel. And we have 
\begin{equation}
	\begin{aligned}
	\|K\|^2_2 &\le  \left \|
	S^TF^T  \mathcal{P}FS
	\right\|_2+  \left \|
	S^TF^T G^T \mathcal{P}GFS
	\right\|_2 \\
	&\le k(\left \|
	F^T  \mathcal{P}F
	\right\|_2+  \left \|
	F^T G^T \mathcal{P}GF
	\right\|_2) \\
	&\le k(1+C)
	\end{aligned}
\end{equation}

\end{document}
